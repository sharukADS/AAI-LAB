{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d83013e-fd21-48cd-b7e6-5d66d619bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(y):\n",
    "    return 1 - y**2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "X = np.array([[1, 1, 0, 1]])\n",
    "y = np.array([[1]])\n",
    "\n",
    "lr = 0.74\n",
    "tolerance = 0.001\n",
    "max_epochs = 10000  # safety cap\n",
    "\n",
    "W1 = np.random.randn(4, 3)\n",
    "b1 = np.zeros((1, 3))\n",
    "\n",
    "W2 = np.random.randn(3, 2)\n",
    "b2 = np.zeros((1, 2))\n",
    "\n",
    "W3 = np.random.randn(2, 1)\n",
    "b3 = np.zeros((1, 1))\n",
    "\n",
    "epoch = 0\n",
    "while epoch < max_epochs:\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    h1 = tanh(z1)\n",
    "\n",
    "    z2 = np.dot(h1, W2) + b2\n",
    "    h2 = tanh(z2)\n",
    "\n",
    "    z3 = np.dot(h2, W3) + b3\n",
    "    o = sigmoid(z3)\n",
    "\n",
    "    # Error\n",
    "    error = y - o\n",
    "\n",
    "    delta_out = error * sigmoid_derivative(o)\n",
    "    delta_h2 = delta_out.dot(W3.T) * tanh_derivative(h2)\n",
    "    delta_h1 = delta_h2.dot(W2.T) * tanh_derivative(h1)\n",
    "\n",
    "    # Update weights and biases\n",
    "    W3 += lr * h2.T.dot(delta_out)\n",
    "    b3 += lr * delta_out\n",
    "\n",
    "    W2 += lr * h1.T.dot(delta_h2)\n",
    "    b2 += lr * delta_h2\n",
    "\n",
    "    W1 += lr * X.T.dot(delta_h1)\n",
    "    b1 += lr * delta_h1\n",
    "\n",
    "    # Check convergence\n",
    "    if abs(error[0][0]) < tolerance:\n",
    "        print(\"Converged at epoch:\", epoch)\n",
    "        print(\"Output (O):\", o)\n",
    "        print(\"Error (D - O):\", error)\n",
    "        print(\"Updated W1:\\n\", W1)\n",
    "        print(\"Updated b1:\\n\", b1)\n",
    "        print(\"Updated W2:\\n\", W2)\n",
    "        print(\"Updated b2:\\n\", b2)\n",
    "        break\n",
    "\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1533be-7266-4a61-a523-f52a86d0a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at epoch: 194\n",
      "Output (O): [[0.9554197]]\n",
      "MSE: 0.0009937016008367034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Activation functions and derivatives ---\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -50, 50)  # prevent overflow\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(y):\n",
    "    return 1 - y**2\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(y):\n",
    "    return (y > 0).astype(float)\n",
    "\n",
    "# Dictionary for easy selection\n",
    "activations = {\n",
    "    \"sigmoid\": (sigmoid, sigmoid_derivative),\n",
    "    \"tanh\": (tanh, tanh_derivative),\n",
    "    \"relu\": (relu, relu_derivative)\n",
    "}\n",
    "\n",
    "# --- Training setup ---\n",
    "X = np.array([[1, 1, 0, 1]], dtype=np.float64)\n",
    "y = np.array([[1]], dtype=np.float64)\n",
    "\n",
    "lr = 0.05\n",
    "tolerance = 1e-3\n",
    "max_epochs = 10000\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "W1 = rng.normal(0, 1, (4, 3))\n",
    "b1 = np.zeros((1, 3))\n",
    "\n",
    "W2 = rng.normal(0, 1, (3, 2))\n",
    "b2 = np.zeros((1, 2))\n",
    "\n",
    "W3 = rng.normal(0, 1, (2, 1))\n",
    "b3 = np.zeros((1, 1))\n",
    "\n",
    "# Choose activation per layer\n",
    "act1, d_act1 = activations[\"tanh\"]\n",
    "act2, d_act2 = activations[\"relu\"]\n",
    "act3, d_act3 = activations[\"tanh\"]  # output layer\n",
    "\n",
    "# --- Training loop ---\n",
    "epoch = 0\n",
    "while epoch < max_epochs:\n",
    "    # Forward pass\n",
    "    z1 = X.dot(W1) + b1\n",
    "    h1 = act1(z1)\n",
    "\n",
    "    z2 = h1.dot(W2) + b2\n",
    "    h2 = act2(z2)\n",
    "\n",
    "    z3 = h2.dot(W3) + b3\n",
    "    o = act3(z3)\n",
    "\n",
    "    # Error and loss\n",
    "    error = y - o\n",
    "    mse = 0.5 * np.mean(error**2)\n",
    "\n",
    "    # Backpropagation\n",
    "    delta_out = (o - y) * d_act3(o)\n",
    "    delta_h2 = delta_out.dot(W3.T) * d_act2(h2)\n",
    "    delta_h1 = delta_h2.dot(W2.T) * d_act1(h1)\n",
    "\n",
    "    # Update weights and biases\n",
    "    W3 -= lr * h2.T.dot(delta_out)\n",
    "    b3 -= lr * delta_out\n",
    "\n",
    "    W2 -= lr * h1.T.dot(delta_h2)\n",
    "    b2 -= lr * delta_h2\n",
    "\n",
    "    W1 -= lr * X.T.dot(delta_h1)\n",
    "    b1 -= lr * delta_h1\n",
    "\n",
    "    # Convergence check\n",
    "    if mse < tolerance:\n",
    "        print(\"Converged at epoch:\", epoch)\n",
    "        print(\"Output (O):\", o)\n",
    "        print(\"MSE:\", mse)\n",
    "        break\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "if epoch == max_epochs and mse >= tolerance:\n",
    "    print(\"Did not converge within max_epochs.\")\n",
    "    print(\"Last Output (O):\", o)\n",
    "    print(\"Final MSE:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "211d7218-280a-474d-99b4-df002a158fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at epoch: 38\n",
      "Output (O): [[0.95530503]]\n",
      "E: 0.0009988201092671605\n",
      "Updated W1:\n",
      " [[ 0.40040796 -1.03998411  1.04724543]\n",
      " [ 1.0362556  -1.95103519 -1.00538527]\n",
      " [ 0.1278404  -0.31624259 -0.01680116]\n",
      " [-0.75735305  0.87939797  1.07458617]]\n",
      "Updated b1:\n",
      " [[0.09569088 0.         0.29679424]]\n",
      "Updated W2:\n",
      " [[ 0.35528704  1.12400792]\n",
      " [ 0.46750934 -0.85929246]\n",
      " [ 0.77805364 -0.96139341]]\n",
      "Updated b2:\n",
      " [[ 0.57116743 -0.00817777]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -50, 50)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_derivative(y):\n",
    "    return y * (1 - y)\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def tanh_derivative(y):\n",
    "    return 1 - y**2\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "def relu_derivative(y):\n",
    "    return (y > 0).astype(float)\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "def leaky_relu_derivative(y, alpha=0.01):\n",
    "    return np.where(y > 0, 1, alpha)\n",
    "def swish(x):\n",
    "    return x * sigmoid(x)\n",
    "def swish_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s + x * s * (1 - s)\n",
    "activations = {\n",
    "    \"sigmoid\": (sigmoid, sigmoid_derivative),\n",
    "    \"tanh\": (tanh, tanh_derivative),\n",
    "    \"relu\": (relu, relu_derivative),\n",
    "    \"leakyrelu\": (leaky_relu, leaky_relu_derivative),\n",
    "    \"swish\": (swish, swish_derivative)\n",
    "}\n",
    "X = np.array([[1, 1, 0, 1]], dtype=np.float64)\n",
    "y = np.array([[1]], dtype=np.float64)\n",
    "lr = 0.74          \n",
    "tolerance = 1e-3  \n",
    "rng = np.random.default_rng(42)\n",
    "W1 = rng.normal(0, 1, (4, 3))\n",
    "b1 = np.zeros((1, 3))\n",
    "W2 = rng.normal(0, 1, (3, 2))\n",
    "b2 = np.zeros((1, 2))\n",
    "W3 = rng.normal(0, 1, (2, 1))\n",
    "b3 = np.zeros((1, 1))\n",
    "act1, d_act1 = activations[\"relu\"]       \n",
    "act2, d_act2 = activations[\"relu\"]   \n",
    "act3, d_act3 = activations[\"sigmoid\"]     \n",
    "epoch = 0\n",
    "while True:\n",
    "    z1 = X.dot(W1) + b1\n",
    "    h1 = act1(z1)\n",
    "    z2 = h1.dot(W2) + b2\n",
    "    h2 = act2(z2)\n",
    "    z3 = h2.dot(W3) + b3\n",
    "    o = act3(z3)\n",
    "    error = y - o\n",
    "    mse = 0.5 * np.mean(error**2)\n",
    "    delta_out = (o - y) * d_act3(o)\n",
    "    delta_h2 = delta_out.dot(W3.T) * d_act2(h2)\n",
    "    delta_h1 = delta_h2.dot(W2.T) * d_act1(h1)\n",
    "    W3 -= lr * h2.T.dot(delta_out)\n",
    "    b3 -= lr * delta_out\n",
    "    W2 -= lr * h1.T.dot(delta_h2)\n",
    "    b2 -= lr * delta_h2\n",
    "    W1 -= lr * X.T.dot(delta_h1)\n",
    "    b1 -= lr * delta_h1\n",
    "    if mse < tolerance:\n",
    "        print(\"Converged at epoch:\", epoch)\n",
    "        print(\"Output (O):\", o)\n",
    "        print(\"E:\", mse)\n",
    "        print(\"Updated W1:\\n\", W1)\n",
    "        print(\"Updated b1:\\n\", b1)\n",
    "        print(\"Updated W2:\\n\", W2)\n",
    "        print(\"Updated b2:\\n\", b2)\n",
    "        break\n",
    "        break\n",
    "\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81898850-501c-468a-9e2c-6835dc052b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at epoch: 676\n",
      "Output (Softmax): [[0.00099949 0.99900051]]\n",
      "Loss: 0.000999986191424735\n",
      "\n",
      "Updated W1:\n",
      " [[ 0.05075092 -1.03998411  0.80502349]\n",
      " [ 0.68659856 -1.95103519 -1.24760721]\n",
      " [ 0.1278404  -0.31624259 -0.01680116]\n",
      " [-1.10701008  0.87939797  0.83236423]]\n",
      "Updated b1:\n",
      " [[-0.25396616  0.          0.0545723 ]]\n",
      "\n",
      "Updated W2:\n",
      " [[-0.08301365  1.04760107]\n",
      " [ 0.46750934 -0.85929246]\n",
      " [ 0.28285009 -1.00478265]]\n",
      "Updated b2:\n",
      " [[-0.37998458 -0.2030404 ]]\n",
      "\n",
      "Updated W3:\n",
      " [[ 0.8337298  -0.00520541]\n",
      " [-0.27710971 -0.58868219]]\n",
      "Updated b3:\n",
      " [[-3.45437365  3.45437365]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "def relu_derivative(y):\n",
    "    return (y > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "X = np.array([[1, 1, 0, 1]], dtype=np.float64)\n",
    "y = np.array([[0, 1]], dtype=np.float64)\n",
    "lr = 0.74\n",
    "tolerance = 1e-3\n",
    "epoch = 0\n",
    "rng = np.random.default_rng(42)\n",
    "W1 = rng.normal(0, 1, (4, 3))\n",
    "b1 = np.zeros((1, 3))\n",
    "W2 = rng.normal(0, 1, (3, 2))\n",
    "b2 = np.zeros((1, 2))\n",
    "W3 = rng.normal(0, 1, (2, 2))\n",
    "b3 = np.zeros((1, 2))\n",
    "act1, d_act1 = relu, relu_derivative\n",
    "act2, d_act2 = relu, relu_derivative\n",
    "act3 = softmax   \n",
    "while True:\n",
    "    z1 = X.dot(W1) + b1\n",
    "    h1 = act1(z1)\n",
    "    z2 = h1.dot(W2) + b2\n",
    "    h2 = act2(z2)\n",
    "    z3 = h2.dot(W3) + b3\n",
    "    o = act3(z3)\n",
    "    loss = -np.mean(np.sum(y * np.log(o + 1e-9), axis=1))\n",
    "    delta_out = o - y\n",
    "    delta_h2 = delta_out.dot(W3.T) * d_act2(h2)\n",
    "    delta_h1 = delta_h2.dot(W2.T) * d_act1(h1)\n",
    "    W3 -= lr * h2.T.dot(delta_out)\n",
    "    b3 -= lr * delta_out\n",
    "    W2 -= lr * h1.T.dot(delta_h2)\n",
    "    b2 -= lr * delta_h2\n",
    "    W1 -= lr * X.T.dot(delta_h1)\n",
    "    b1 -= lr * delta_h1\n",
    "    if loss < tolerance:\n",
    "        print(\"Converged at epoch:\", epoch)\n",
    "        print(\"Output (Softmax):\", o)\n",
    "        print(\"Loss:\", loss)\n",
    "        print(\"\\nUpdated W1:\\n\", W1)\n",
    "        print(\"Updated b1:\\n\", b1)\n",
    "        print(\"\\nUpdated W2:\\n\", W2)\n",
    "        print(\"Updated b2:\\n\", b2)\n",
    "        print(\"\\nUpdated W3:\\n\", W3)\n",
    "        print(\"Updated b3:\\n\", b3)\n",
    "        break\n",
    "\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9cf0c7-ee44-4185-a607-25a5660edea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
